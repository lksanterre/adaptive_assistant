{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Conv1D, Embedding, GlobalMaxPooling1D,\n",
    "                                    LSTM, Dense, Dropout, Bidirectional)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1728527699758, experiment_id='1', last_update_time=1728527699758, lifecycle_stage='active', name='intern-question/project/final/mlflow', tags={}>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri('https://mlflow-serv-1073438601911.us-west2.run.app')\n",
    "mlflow.set_experiment('intern-question/project/final/mlflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            question           labels\n",
      "0  Which NFL team represented the AFC at Super Bo...  [1.0, 0.0, 0.0]\n",
      "1  Which NFL team represented the NFC at Super Bo...  [1.0, 0.0, 0.0]\n",
      "2                Where did Super Bowl 50 take place?  [1.0, 0.0, 0.0]\n",
      "3                  Which NFL team won Super Bowl 50?  [1.0, 0.0, 0.0]\n",
      "4  What color was used to emphasize the 50th anni...  [1.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         Which NFL team represented the AFC at Super Bo...\n",
       "1         Which NFL team represented the NFC at Super Bo...\n",
       "2                       Where did Super Bowl 50 take place?\n",
       "3                         Which NFL team won Super Bowl 50?\n",
       "4         What color was used to emphasize the 50th anni...\n",
       "                                ...                        \n",
       "414915    How many keywords are there in the Racket prog...\n",
       "414916            Do you believe there is life after death?\n",
       "414917                                    What is one coin?\n",
       "414918    What is the approx annual cost of living while...\n",
       "414919                What is like to have sex with cousin?\n",
       "Name: question, Length: 414920, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/Users/lancesanterre/pipeline_edu/data/processed/pipeline_and_data.pkl', 'rb') as f:\n",
    "    df = pd.read_pickle(f)\n",
    "print(df.head())\n",
    "# Assuming the DataFrame `df` has at least one column and you want to access the first column\n",
    "questions = df['question']  # or df[0] if it's a Series or DataFrame\n",
    "questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_labels = df['labels']\n",
    "filtered_questions = questions "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.8782 - loss: 0.3157 - val_accuracy: 0.9249 - val_loss: 0.1880\n",
      "Epoch 2/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.9227 - loss: 0.1948 - val_accuracy: 0.9316 - val_loss: 0.1717\n",
      "Epoch 3/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.9314 - loss: 0.1761 - val_accuracy: 0.9352 - val_loss: 0.1669\n",
      "Epoch 4/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.9343 - loss: 0.1658 - val_accuracy: 0.9369 - val_loss: 0.1627\n",
      "Epoch 5/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.9374 - loss: 0.1581 - val_accuracy: 0.9384 - val_loss: 0.1609\n",
      "Epoch 6/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.9394 - loss: 0.1538 - val_accuracy: 0.9388 - val_loss: 0.1602\n",
      "Epoch 7/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.9408 - loss: 0.1520 - val_accuracy: 0.9394 - val_loss: 0.1586\n",
      "Epoch 8/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.9419 - loss: 0.1472 - val_accuracy: 0.9405 - val_loss: 0.1622\n",
      "Epoch 9/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.9432 - loss: 0.1450 - val_accuracy: 0.9406 - val_loss: 0.1634\n",
      "Epoch 10/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.9447 - loss: 0.1413 - val_accuracy: 0.9414 - val_loss: 0.1577\n",
      "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 361us/step - accuracy: 0.9404 - loss: 0.1597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/09 20:16:52 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/10/09 20:16:57 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/10/09 20:16:57 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run monumental-koi-200 at: https://mlflow-serv-1073438601911.us-west2.run.app/#/experiments/1/runs/6080a94451f34086995b5de913c5507e.\n",
      "2024/10/09 20:16:57 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: https://mlflow-serv-1073438601911.us-west2.run.app/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as Simple_LSTM_1000_16 with accuracy: 0.94\n",
      "Epoch 1/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.8870 - loss: 0.2865 - val_accuracy: 0.9320 - val_loss: 0.1684\n",
      "Epoch 2/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.9312 - loss: 0.1735 - val_accuracy: 0.9374 - val_loss: 0.1569\n",
      "Epoch 3/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.9389 - loss: 0.1552 - val_accuracy: 0.9398 - val_loss: 0.1510\n",
      "Epoch 4/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.9427 - loss: 0.1461 - val_accuracy: 0.9418 - val_loss: 0.1509\n",
      "Epoch 5/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.1401 - val_accuracy: 0.9424 - val_loss: 0.1457\n",
      "Epoch 6/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.9482 - loss: 0.1331 - val_accuracy: 0.9447 - val_loss: 0.1432\n",
      "Epoch 7/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.9503 - loss: 0.1290 - val_accuracy: 0.9453 - val_loss: 0.1416\n",
      "Epoch 8/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.9526 - loss: 0.1234 - val_accuracy: 0.9460 - val_loss: 0.1414\n",
      "Epoch 9/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.9536 - loss: 0.1216 - val_accuracy: 0.9457 - val_loss: 0.1414\n",
      "Epoch 10/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step - accuracy: 0.9554 - loss: 0.1165 - val_accuracy: 0.9469 - val_loss: 0.1431\n",
      "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 493us/step - accuracy: 0.9464 - loss: 0.1452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/09 20:19:21 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/10/09 20:19:26 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/10/09 20:19:26 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run crawling-auk-234 at: https://mlflow-serv-1073438601911.us-west2.run.app/#/experiments/1/runs/ba6477d00dfd49e7bc50095549ea44f0.\n",
      "2024/10/09 20:19:26 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: https://mlflow-serv-1073438601911.us-west2.run.app/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as Simple_LSTM_1000_32 with accuracy: 0.95\n",
      "Epoch 1/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - accuracy: 0.8991 - loss: 0.2559 - val_accuracy: 0.9349 - val_loss: 0.1626\n",
      "Epoch 2/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - accuracy: 0.9362 - loss: 0.1608 - val_accuracy: 0.9396 - val_loss: 0.1516\n",
      "Epoch 3/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - accuracy: 0.9433 - loss: 0.1441 - val_accuracy: 0.9429 - val_loss: 0.1443\n",
      "Epoch 4/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - accuracy: 0.9475 - loss: 0.1345 - val_accuracy: 0.9433 - val_loss: 0.1424\n",
      "Epoch 5/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - accuracy: 0.9502 - loss: 0.1274 - val_accuracy: 0.9451 - val_loss: 0.1400\n",
      "Epoch 6/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - accuracy: 0.9536 - loss: 0.1193 - val_accuracy: 0.9460 - val_loss: 0.1387\n",
      "Epoch 7/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - accuracy: 0.9564 - loss: 0.1133 - val_accuracy: 0.9458 - val_loss: 0.1388\n",
      "Epoch 8/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - accuracy: 0.9588 - loss: 0.1071 - val_accuracy: 0.9474 - val_loss: 0.1402\n",
      "Epoch 9/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - accuracy: 0.9619 - loss: 0.1011 - val_accuracy: 0.9468 - val_loss: 0.1388\n",
      "Epoch 10/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.0963 - val_accuracy: 0.9487 - val_loss: 0.1445\n",
      "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 706us/step - accuracy: 0.9488 - loss: 0.1473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/09 20:23:54 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/10/09 20:23:59 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/10/09 20:23:59 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run masked-sloth-629 at: https://mlflow-serv-1073438601911.us-west2.run.app/#/experiments/1/runs/7d167d35c9904db29285d0fc1f33d1bf.\n",
      "2024/10/09 20:23:59 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: https://mlflow-serv-1073438601911.us-west2.run.app/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as Simple_LSTM_1000_64 with accuracy: 0.95\n",
      "Epoch 1/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.8639 - loss: 0.3485 - val_accuracy: 0.9145 - val_loss: 0.2090\n",
      "Epoch 2/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.9144 - loss: 0.2153 - val_accuracy: 0.9223 - val_loss: 0.1934\n",
      "Epoch 3/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.9214 - loss: 0.1966 - val_accuracy: 0.9251 - val_loss: 0.1914\n",
      "Epoch 4/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.1851 - val_accuracy: 0.9271 - val_loss: 0.1927\n",
      "Epoch 5/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.9307 - loss: 0.1764 - val_accuracy: 0.9275 - val_loss: 0.1926\n",
      "Epoch 6/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.9335 - loss: 0.1678 - val_accuracy: 0.9296 - val_loss: 0.1824\n",
      "Epoch 7/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.9359 - loss: 0.1638 - val_accuracy: 0.9294 - val_loss: 0.1949\n",
      "Epoch 8/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.9382 - loss: 0.1587 - val_accuracy: 0.9300 - val_loss: 0.1876\n",
      "Epoch 9/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.9398 - loss: 0.1541 - val_accuracy: 0.9311 - val_loss: 0.1830\n",
      "Epoch 10/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - accuracy: 0.9413 - loss: 0.1520 - val_accuracy: 0.9299 - val_loss: 0.1878\n",
      "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 361us/step - accuracy: 0.9293 - loss: 0.1877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/09 20:25:59 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/10/09 20:26:07 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/10/09 20:26:07 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run receptive-shrimp-928 at: https://mlflow-serv-1073438601911.us-west2.run.app/#/experiments/1/runs/f30d0c2a691f4be59c260e932c0677f5.\n",
      "2024/10/09 20:26:07 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: https://mlflow-serv-1073438601911.us-west2.run.app/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as Simple_LSTM_2000_16 with accuracy: 0.93\n",
      "Epoch 1/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.8713 - loss: 0.3231 - val_accuracy: 0.9192 - val_loss: 0.1962\n",
      "Epoch 2/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.9215 - loss: 0.1949 - val_accuracy: 0.9252 - val_loss: 0.1869\n",
      "Epoch 3/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.9305 - loss: 0.1751 - val_accuracy: 0.9302 - val_loss: 0.1737\n",
      "Epoch 4/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9359 - loss: 0.1629 - val_accuracy: 0.9318 - val_loss: 0.1720\n",
      "Epoch 5/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9404 - loss: 0.1530 - val_accuracy: 0.9333 - val_loss: 0.1706\n",
      "Epoch 6/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9426 - loss: 0.1457 - val_accuracy: 0.9338 - val_loss: 0.1740\n",
      "Epoch 7/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9462 - loss: 0.1388 - val_accuracy: 0.9335 - val_loss: 0.1729\n",
      "Epoch 8/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.9491 - loss: 0.1312 - val_accuracy: 0.9348 - val_loss: 0.1731\n",
      "Epoch 9/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9514 - loss: 0.1261 - val_accuracy: 0.9343 - val_loss: 0.1776\n",
      "Epoch 10/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - accuracy: 0.9542 - loss: 0.1195 - val_accuracy: 0.9348 - val_loss: 0.1806\n",
      "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444us/step - accuracy: 0.9350 - loss: 0.1801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/09 20:28:57 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/10/09 20:29:04 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/10/09 20:29:04 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run suave-seal-2 at: https://mlflow-serv-1073438601911.us-west2.run.app/#/experiments/1/runs/cfd93dbcef0f492890a9134aca086a27.\n",
      "2024/10/09 20:29:04 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: https://mlflow-serv-1073438601911.us-west2.run.app/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as Simple_LSTM_2000_32 with accuracy: 0.93\n",
      "Epoch 1/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - accuracy: 0.8828 - loss: 0.2931 - val_accuracy: 0.9225 - val_loss: 0.1915\n",
      "Epoch 2/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - accuracy: 0.9254 - loss: 0.1851 - val_accuracy: 0.9291 - val_loss: 0.1763\n",
      "Epoch 3/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - accuracy: 0.9342 - loss: 0.1653 - val_accuracy: 0.9318 - val_loss: 0.1712\n",
      "Epoch 4/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - accuracy: 0.9398 - loss: 0.1532 - val_accuracy: 0.9342 - val_loss: 0.1670\n",
      "Epoch 5/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - accuracy: 0.9453 - loss: 0.1406 - val_accuracy: 0.9352 - val_loss: 0.1656\n",
      "Epoch 6/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - accuracy: 0.9502 - loss: 0.1296 - val_accuracy: 0.9368 - val_loss: 0.1683\n",
      "Epoch 7/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.1210 - val_accuracy: 0.9366 - val_loss: 0.1691\n",
      "Epoch 8/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - accuracy: 0.9574 - loss: 0.1118 - val_accuracy: 0.9377 - val_loss: 0.1785\n",
      "Epoch 9/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - accuracy: 0.9607 - loss: 0.1039 - val_accuracy: 0.9377 - val_loss: 0.1769\n",
      "Epoch 10/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.0977 - val_accuracy: 0.9377 - val_loss: 0.1869\n",
      "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 698us/step - accuracy: 0.9378 - loss: 0.1879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/09 20:34:08 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/10/09 20:34:13 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/10/09 20:34:14 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run caring-finch-58 at: https://mlflow-serv-1073438601911.us-west2.run.app/#/experiments/1/runs/1226e0bae6c64f83be0ec2edcd207e23.\n",
      "2024/10/09 20:34:14 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: https://mlflow-serv-1073438601911.us-west2.run.app/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as Simple_LSTM_2000_64 with accuracy: 0.94\n",
      "Registering the best model: Simple_LSTM_1000_64 with accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Best_Simple_LSTM_Model'.\n",
      "2024/10/09 20:34:14 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Best_Simple_LSTM_Model, version 1\n",
      "Created version '1' of model 'Best_Simple_LSTM_Model'.\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "best_model_info = None\n",
    "\n",
    "for input_dim in [1000, 2000]:\n",
    "    for output_dim in [16, 32, 64]:\n",
    "        input_length = 10\n",
    "        with mlflow.start_run():\n",
    "            # Tokenization and Padding\n",
    "            tokenizer = Tokenizer(num_words=input_dim)  # Adjust vocabulary size\n",
    "            tokenizer.fit_on_texts(filtered_questions)\n",
    "            sequences = tokenizer.texts_to_sequences(filtered_questions)\n",
    "            X = pad_sequences(sequences, maxlen=input_length)\n",
    "\n",
    "            # Convert labels to numpy array\n",
    "            y = np.array(filtered_labels.tolist())\n",
    "\n",
    "            # Model: Simple LSTM\n",
    "            model_name = f\"Simple_LSTM_{input_dim}_{output_dim}\"\n",
    "            model = Sequential([\n",
    "                Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length),\n",
    "                LSTM(output_dim),\n",
    "                Dropout(0.5),\n",
    "                Dense(32, activation='relu'),\n",
    "                Dense(3, activation='softmax')\n",
    "            ])\n",
    "\n",
    "            # Compile and train\n",
    "            model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "            # Evaluate and log\n",
    "            loss, accuracy = model.evaluate(X_test, y_test)\n",
    "            mlflow.log_params({\"input_dim\": input_dim, \"output_dim\": output_dim, \"input_length\": input_length})\n",
    "            mlflow.log_metrics({\"loss\": loss, \"accuracy\": accuracy})\n",
    "\n",
    "            # Save the model with a unique name\n",
    "            mlflow.keras.log_model(model, artifact_path=model_name)\n",
    "            print(f\"Model saved as {model_name} with accuracy: {accuracy:.2f}\")\n",
    "\n",
    "            # Check if this is the best model\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_model_info = {\n",
    "                    \"model_name\": model_name,\n",
    "                    \"run_id\": mlflow.active_run().info.run_id,\n",
    "                }\n",
    "\n",
    "            # End the current MLflow run to prepare for the next iteration\n",
    "            mlflow.end_run()\n",
    "\n",
    "# Register the best model\n",
    "if best_model_info:\n",
    "    print(f\"Registering the best model: {best_model_info['model_name']} with accuracy: {best_accuracy:.2f}\")\n",
    "    mlflow.register_model(\n",
    "        model_uri=f\"runs:/{best_model_info['run_id']}/{best_model_info['model_name']}\",\n",
    "        name=\"Best_Simple_LSTM_Model\"\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Bi-directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.8889 - loss: 0.2822 - val_accuracy: 0.9315 - val_loss: 0.1724\n",
      "Epoch 2/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.9318 - loss: 0.1752 - val_accuracy: 0.9358 - val_loss: 0.1610\n",
      "Epoch 3/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.9370 - loss: 0.1604 - val_accuracy: 0.9384 - val_loss: 0.1552\n",
      "Epoch 4/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.9404 - loss: 0.1530 - val_accuracy: 0.9400 - val_loss: 0.1510\n",
      "Epoch 5/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.9431 - loss: 0.1461 - val_accuracy: 0.9417 - val_loss: 0.1476\n",
      "Epoch 6/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.9444 - loss: 0.1433 - val_accuracy: 0.9419 - val_loss: 0.1477\n",
      "Epoch 7/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.9460 - loss: 0.1386 - val_accuracy: 0.9417 - val_loss: 0.1483\n",
      "Epoch 8/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.9470 - loss: 0.1373 - val_accuracy: 0.9436 - val_loss: 0.1453\n",
      "Epoch 9/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.9490 - loss: 0.1325 - val_accuracy: 0.9436 - val_loss: 0.1458\n",
      "Epoch 10/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.1295 - val_accuracy: 0.9447 - val_loss: 0.1434\n",
      "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - accuracy: 0.9438 - loss: 0.1456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/22 18:21:22 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/09/22 18:21:28 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/09/22 18:21:28 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run defiant-ape-959 at: https://mlflow-service-1073438601911.us-west2.run.app/#/experiments/1/runs/25c22f52e35347ecb89e47e6ceee9b16.\n",
      "2024/09/22 18:21:28 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: https://mlflow-service-1073438601911.us-west2.run.app/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as Bidirectional_LSTM_1000_16 with accuracy: 0.94\n",
      "Epoch 1/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - accuracy: 0.8969 - loss: 0.2613 - val_accuracy: 0.9341 - val_loss: 0.1660\n",
      "Epoch 2/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - accuracy: 0.9350 - loss: 0.1647 - val_accuracy: 0.9386 - val_loss: 0.1524\n",
      "Epoch 3/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - accuracy: 0.9416 - loss: 0.1486 - val_accuracy: 0.9409 - val_loss: 0.1488\n",
      "Epoch 4/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - accuracy: 0.9453 - loss: 0.1390 - val_accuracy: 0.9418 - val_loss: 0.1465\n",
      "Epoch 5/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - accuracy: 0.9483 - loss: 0.1328 - val_accuracy: 0.9429 - val_loss: 0.1437\n",
      "Epoch 6/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - accuracy: 0.9505 - loss: 0.1282 - val_accuracy: 0.9449 - val_loss: 0.1444\n",
      "Epoch 7/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.1226 - val_accuracy: 0.9459 - val_loss: 0.1391\n",
      "Epoch 8/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - accuracy: 0.9544 - loss: 0.1184 - val_accuracy: 0.9452 - val_loss: 0.1407\n",
      "Epoch 9/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.1148 - val_accuracy: 0.9455 - val_loss: 0.1450\n",
      "Epoch 10/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.1102 - val_accuracy: 0.9469 - val_loss: 0.1433\n",
      "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 837us/step - accuracy: 0.9466 - loss: 0.1450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/22 18:26:09 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/09/22 18:26:17 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/09/22 18:26:17 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run likeable-snake-443 at: https://mlflow-service-1073438601911.us-west2.run.app/#/experiments/1/runs/42e5bb57663847d1984a7c5848ca5897.\n",
      "2024/09/22 18:26:17 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: https://mlflow-service-1073438601911.us-west2.run.app/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as Bidirectional_LSTM_1000_32 with accuracy: 0.95\n",
      "Epoch 1/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 5ms/step - accuracy: 0.9047 - loss: 0.2403 - val_accuracy: 0.9366 - val_loss: 0.1585\n",
      "Epoch 2/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5ms/step - accuracy: 0.9392 - loss: 0.1533 - val_accuracy: 0.9426 - val_loss: 0.1458\n",
      "Epoch 3/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5ms/step - accuracy: 0.9449 - loss: 0.1393 - val_accuracy: 0.9437 - val_loss: 0.1418\n",
      "Epoch 4/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 5ms/step - accuracy: 0.9495 - loss: 0.1301 - val_accuracy: 0.9448 - val_loss: 0.1405\n",
      "Epoch 5/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5ms/step - accuracy: 0.9532 - loss: 0.1209 - val_accuracy: 0.9467 - val_loss: 0.1366\n",
      "Epoch 6/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5ms/step - accuracy: 0.9563 - loss: 0.1138 - val_accuracy: 0.9487 - val_loss: 0.1356\n",
      "Epoch 7/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5ms/step - accuracy: 0.9591 - loss: 0.1061 - val_accuracy: 0.9492 - val_loss: 0.1369\n",
      "Epoch 8/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5ms/step - accuracy: 0.9619 - loss: 0.1000 - val_accuracy: 0.9489 - val_loss: 0.1414\n",
      "Epoch 9/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 5ms/step - accuracy: 0.9654 - loss: 0.0923 - val_accuracy: 0.9505 - val_loss: 0.1402\n",
      "Epoch 10/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 4ms/step - accuracy: 0.9677 - loss: 0.0866 - val_accuracy: 0.9498 - val_loss: 0.1405\n",
      "\u001b[1m2594/2594\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9492 - loss: 0.1424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/22 18:34:46 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/09/22 18:34:58 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/09/22 18:34:58 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run bouncy-cow-286 at: https://mlflow-service-1073438601911.us-west2.run.app/#/experiments/1/runs/e4352c9a0f1f4b169800149bd3620954.\n",
      "2024/09/22 18:34:58 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: https://mlflow-service-1073438601911.us-west2.run.app/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as Bidirectional_LSTM_1000_64 with accuracy: 0.95\n",
      "Epoch 1/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 12ms/step - accuracy: 0.9084 - loss: 0.2295 - val_accuracy: 0.9386 - val_loss: 0.1547\n",
      "Epoch 2/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 13ms/step - accuracy: 0.9404 - loss: 0.1511 - val_accuracy: 0.9430 - val_loss: 0.1444\n",
      "Epoch 3/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 12ms/step - accuracy: 0.9487 - loss: 0.1318 - val_accuracy: 0.9471 - val_loss: 0.1349\n",
      "Epoch 4/10\n",
      "\u001b[1m10373/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 13ms/step - accuracy: 0.9532 - loss: 0.1205 - val_accuracy: 0.9471 - val_loss: 0.1357\n",
      "Epoch 5/10\n",
      "\u001b[1m10116/10373\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9583 - loss: 0.1080"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/22 18:45:52 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gentle-rook-187 at: https://mlflow-service-1073438601911.us-west2.run.app/#/experiments/1/runs/4ae09ce00629496fb41f0fe627bce2e6.\n",
      "2024/09/22 18:45:52 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: https://mlflow-service-1073438601911.us-west2.run.app/#/experiments/1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     24\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test))\n\u001b[1;32m     27\u001b[0m \u001b[39m# Evaluate and log\u001b[39;00m\n\u001b[1;32m     28\u001b[0m loss, accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/intern/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/intern/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mfor\u001b[39;00m step, iterator \u001b[39min\u001b[39;00m epoch_iterator\u001b[39m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m    321\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    322\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/intern/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/intern/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/intern/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/intern/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/intern/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/intern/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_preflattened\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_flat(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    217\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/intern/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    253\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/intern/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1553\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1554\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1555\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1556\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1557\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1558\u001b[0m   )\n\u001b[1;32m   1559\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/intern/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for input_dim in [1000, 2000, 4000, 5000]:\n",
    "    for output_dim in [16, 32, 64, 128]:\n",
    "        input_length = 10\n",
    "        with mlflow.start_run():\n",
    "            # Tokenization and Padding\n",
    "            tokenizer = Tokenizer(num_words=input_dim)\n",
    "            tokenizer.fit_on_texts(filtered_questions)\n",
    "            sequences = tokenizer.texts_to_sequences(filtered_questions)\n",
    "            X = pad_sequences(sequences, maxlen=input_length)\n",
    "            y = np.array(filtered_labels.tolist())\n",
    "\n",
    "            # Model 2: Bi-directional LSTM\n",
    "            model_name = f\"Bidirectional_LSTM_{input_dim}_{output_dim}\"\n",
    "            model = Sequential([\n",
    "                Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length),\n",
    "                Bidirectional(LSTM(output_dim)),\n",
    "                Dropout(0.5),\n",
    "                Dense(32, activation='relu'),\n",
    "                Dense(3, activation='softmax')\n",
    "            ])\n",
    "\n",
    "            # Compile and train\n",
    "            model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "            # Evaluate and log\n",
    "            loss, accuracy = model.evaluate(X_test, y_test)\n",
    "            mlflow.log_params({\"input_dim\": input_dim, \"output_dim\": output_dim, \"input_length\": input_length})\n",
    "            mlflow.log_metric(\"loss\", loss)\n",
    "            mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "            # Save the model with a unique name\n",
    "            mlflow.keras.log_model(model, artifact_path=model_name)\n",
    "            print(f\"Model saved as {model_name} with accuracy: {accuracy:.2f}\")\n",
    "        mlflow.end_run()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chosen Model \n",
    "## Bi-directional LSTM\n",
    "### Params\n",
    "- input_dim : 1000\n",
    "- output_dim : 128\n",
    "- input_length : 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer saved at: model_token/tokenizer.pkl\n",
      "Epoch 1/10\n",
      "10373/10373 - 27s - 3ms/step - accuracy: 0.9193 - loss: 0.2048 - val_accuracy: 0.9343 - val_loss: 0.1638\n",
      "Epoch 2/10\n",
      "10373/10373 - 25s - 2ms/step - accuracy: 0.9370 - loss: 0.1591 - val_accuracy: 0.9390 - val_loss: 0.1546\n",
      "Epoch 3/10\n",
      "10373/10373 - 25s - 2ms/step - accuracy: 0.9424 - loss: 0.1460 - val_accuracy: 0.9420 - val_loss: 0.1462\n",
      "Epoch 4/10\n",
      "10373/10373 - 26s - 3ms/step - accuracy: 0.9465 - loss: 0.1363 - val_accuracy: 0.9421 - val_loss: 0.1441\n",
      "Epoch 5/10\n",
      "10373/10373 - 26s - 3ms/step - accuracy: 0.9498 - loss: 0.1284 - val_accuracy: 0.9446 - val_loss: 0.1407\n",
      "Epoch 6/10\n",
      "10373/10373 - 26s - 3ms/step - accuracy: 0.9530 - loss: 0.1210 - val_accuracy: 0.9463 - val_loss: 0.1377\n",
      "Epoch 7/10\n",
      "10373/10373 - 26s - 3ms/step - accuracy: 0.9556 - loss: 0.1151 - val_accuracy: 0.9465 - val_loss: 0.1417\n",
      "Epoch 8/10\n",
      "10373/10373 - 26s - 3ms/step - accuracy: 0.9584 - loss: 0.1090 - val_accuracy: 0.9473 - val_loss: 0.1404\n",
      "Epoch 9/10\n",
      "10373/10373 - 26s - 3ms/step - accuracy: 0.9602 - loss: 0.1040 - val_accuracy: 0.9481 - val_loss: 0.1407\n",
      "Epoch 10/10\n",
      "10373/10373 - 26s - 3ms/step - accuracy: 0.9621 - loss: 0.0989 - val_accuracy: 0.9489 - val_loss: 0.1406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/09 20:14:29 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: model_token/Simple_LSTM_1000_64.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/09 20:14:36 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logged in MLflow as Simple_LSTM_1000_64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/09 20:14:38 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run gentle-skink-895 at: https://mlflow-serv-1073438601911.us-west2.run.app/#/experiments/1/runs/d026d2ad1f3c42508e91da22f21378ec.\n",
      "2024/10/09 20:14:38 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: https://mlflow-serv-1073438601911.us-west2.run.app/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation - Accuracy: 0.95, Loss: 0.14\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Define directories and parameters\n",
    "save_dir = \"model_token\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "input_dim = 1000  # Adjust as needed\n",
    "output_dim = 64  # Adjust as needed\n",
    "input_length = 10  # Should match the training setup\n",
    "\n",
    "# Sample data (assuming filtered_questions and filtered_labels are already defined)\n",
    "# filtered_questions = [...]  # Define your questions list here\n",
    "# filtered_labels = [...]     # Define your labels list here\n",
    "\n",
    "# Tokenization and Padding\n",
    "tokenizer = Tokenizer(num_words=input_dim)\n",
    "tokenizer.fit_on_texts(filtered_questions)\n",
    "sequences = tokenizer.texts_to_sequences(filtered_questions)\n",
    "X = pad_sequences(sequences, maxlen=input_length)\n",
    "y = np.array(filtered_labels.tolist())\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer_path = os.path.join(save_dir, \"tokenizer.pkl\")\n",
    "with open(tokenizer_path, 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "print(f\"Tokenizer saved at: {tokenizer_path}\")\n",
    "\n",
    "# Split data for training and evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Model: Simple LSTM\n",
    "    model_name = f\"Simple_LSTM_{input_dim}_{output_dim}\"\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length),\n",
    "        LSTM(output_dim),\n",
    "        Dropout(0.5),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model with a validation split to monitor training\n",
    "    model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "    # Save the model in the correct format\n",
    "    model_path = os.path.join(save_dir, model_name + \".keras\")\n",
    "    model.save(model_path)\n",
    "    print(f\"Model saved at: {model_path}\")\n",
    "\n",
    "    # Log the model to MLflow\n",
    "    mlflow.log_params({\"input_dim\": input_dim, \"output_dim\": output_dim, \"input_length\": input_length})\n",
    "    mlflow.keras.log_model(model, artifact_path=model_name)\n",
    "    print(f\"Model logged in MLflow as {model_name}\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Model evaluation - Accuracy: {accuracy:.2f}, Loss: {loss:.2f}\")\n",
    "\n",
    "# End the MLflow run\n",
    "mlflow.end_run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
